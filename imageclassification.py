# -*- coding: utf-8 -*-
"""ImageClassification_Task1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1w4kAhU_s7aed3KbLWbxDKb7-iOOYthxP
"""

!pip install tensorflow==2.15.0 tensorflow-hub keras==2.15.0

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import time

import PIL.Image as Image
import matplotlib.pylab as plt

import tensorflow as tf
import tensorflow_hub as hub

import datetime

# %load_ext tensorboard

from google.colab import drive
drive.mount('/content/drive')
import pathlib
#data_dir = "/content/drive/MyDrive/NatureUrbanMix/"
data_dir = "/content/drive/MyDrive/DeepLearning/complexDataset/train/"

data_dir = pathlib.Path(data_dir)

BATCH_SIZE = 32
IMG_SIZE = (224, 224)

train_dataset = tf.keras.utils.image_dataset_from_directory(
  data_dir,
  validation_split=0.2,
  subset="training",
  seed=123,
  image_size=IMG_SIZE,
  batch_size=BATCH_SIZE)

validation_dataset = tf.keras.utils.image_dataset_from_directory(
  data_dir,
  validation_split=0.2,
  subset="validation",
  seed=123,
  image_size=IMG_SIZE,
  batch_size=BATCH_SIZE)

train_ds = train_dataset
val_ds = validation_dataset

class_names = np.array(train_ds.class_names)
print(class_names)

normalization_layer = tf.keras.layers.Rescaling(1./255)
train_ds = train_ds.map(lambda x, y: (normalization_layer(x), y)) # Where x—images, y—labels.
val_ds = val_ds.map(lambda x, y: (normalization_layer(x), y)) # Where x—images, y—labels.

AUTOTUNE = tf.data.AUTOTUNE
train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)
val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)

for image_batch, labels_batch in train_ds:
  print(image_batch.shape)
  print(labels_batch.shape)
  break

mobilenet_v2 = "https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4"
inception_v3 = "https://tfhub.dev/google/tf2-preview/inception_v3/feature_vector/4"

feature_extractor_model = mobilenet_v2 #@param ["mobilenet_v2", "inception_v3"] {type:"raw"}

feature_extractor_layer = hub.KerasLayer(
    feature_extractor_model,
    input_shape=(224, 224, 3),
    trainable=False)

feature_batch = feature_extractor_layer(image_batch)
print(feature_batch.shape)

num_classes = len(class_names)

model = tf.keras.Sequential([
  feature_extractor_layer,
  tf.keras.layers.Dense(num_classes)
])

model.summary()

# Model definition (ensure your feature extractor layer is already created)
model = tf.keras.Sequential([
    feature_extractor_layer,  # Pretrained layer like MobileNetV2 or InceptionV3
    tf.keras.layers.Dense(num_classes)  # Classification head
])

# Hyperparameter tuning: Grid search for learning rate and batch size
learning_rates = [0.001, 0.01, 0.1]
batch_sizes = [16, 32, 64]

# Dictionary to log results
results = {}

for lr in learning_rates:
    for batch_size in batch_sizes:
        print(f"\nTraining with Learning Rate={lr}, Batch Size={batch_size}")

        # Compile the model with current learning rate
        model.compile(
            optimizer=tf.keras.optimizers.Adam(learning_rate=lr),
            loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
            metrics=['accuracy']
        )

        # Train the model with current batch size
        history = model.fit(
            train_ds.batch(batch_size),
            validation_data=val_ds.batch(batch_size),
            epochs=5  # Use fewer epochs for quicker tuning
        )

        # Record validation accuracy for this configuration
        val_accuracy = history.history['val_accuracy'][-1]  # Last epoch validation accuracy
        results[(lr, batch_size)] = val_accuracy

# Print best configuration based on validation accuracy
best_config = max(results, key=results.get)
print(f"\nBest Hyperparameters: Learning Rate={best_config[0]}, Batch Size={best_config[1]}")

predictions = model(image_batch)

predictions.shape

model.compile(
  optimizer=tf.keras.optimizers.Adam(),
  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
  metrics=['acc'])

log_dir = "logs/fit/" + datetime.datetime.now().strftime("%Y%m%d-%H%M%S")
tensorboard_callback = tf.keras.callbacks.TensorBoard(
    log_dir=log_dir,
    histogram_freq=1) # Enable histogram computation for every epoch.

NUM_EPOCHS = 10

history = model.fit(train_ds,
                    validation_data=val_ds,
                    epochs=NUM_EPOCHS,
                    callbacks=tensorboard_callback)

# Commented out IPython magic to ensure Python compatibility.
# %tensorboard --logdir logs/fit

predicted_batch = model.predict(image_batch)
predicted_id = tf.math.argmax(predicted_batch, axis=-1)
predicted_label_batch = class_names[predicted_id]
print(predicted_label_batch)

plt.figure(figsize=(10,9))
plt.subplots_adjust(hspace=0.5)

for n in range(30):
  plt.subplot(6,5,n+1)
  plt.imshow(image_batch[n])
  plt.title(predicted_label_batch[n].title())
  plt.axis('off')
_ = plt.suptitle("Model predictions")

"""models image add in the report, that discuss in the class."""

# Import TensorFlow Hub
import tensorflow_hub as hub
import tensorflow as tf

# Define the InceptionV3 feature extractor layer
inception_feature_extractor = hub.KerasLayer(
    "https://tfhub.dev/google/tf2-preview/inception_v3/feature_vector/4",
    input_shape=(224, 224, 3),
    trainable=False
)

# Define a model for InceptionV3
num_classes = len(class_names)  # Update this based on your dataset
inception_model = tf.keras.Sequential([
    inception_feature_extractor,
    tf.keras.layers.Dense(num_classes)
])

# Compile the model
inception_model.compile(
    optimizer=tf.keras.optimizers.Adam(),
    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
    metrics=['accuracy']
)

# Train the InceptionV3 model
NUM_EPOCHS = 10
inception_history = inception_model.fit(
    train_ds,
    validation_data=val_ds,
    epochs=NUM_EPOCHS
)

# Evaluate the trained InceptionV3 model on validation data
inception_eval_results = inception_model.evaluate(val_ds)
print("InceptionV3 Evaluation Results:", inception_eval_results)

from sklearn.metrics import classification_report, confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt

# Predict on validation set
y_true = []
y_pred = []

for images, labels in val_ds:
    predictions = model.predict(images)
    y_pred.extend(tf.argmax(predictions, axis=1).numpy())
    y_true.extend(labels.numpy())

# Generate classification report
print("MobileNetV2 Classification Report")
print(classification_report(y_true, y_pred, target_names=class_names))

# Plot confusion matrix
cm = confusion_matrix(y_true, y_pred)
plt.figure(figsize=(6, 4))
sns.heatmap(cm, annot=True, fmt='d', xticklabels=class_names, yticklabels=class_names, cmap='Blues')
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('Confusion Matrix: MobileNetV2')
plt.show()

# Predict on validation set
y_true = []
y_pred = []

for images, labels in val_ds:
    predictions = inception_model.predict(images)
    y_pred.extend(tf.argmax(predictions, axis=1).numpy())
    y_true.extend(labels.numpy())

# Generate classification report
print("InceptionV3 Classification Report")
print(classification_report(y_true, y_pred, target_names=class_names))

# Plot confusion matrix
cm = confusion_matrix(y_true, y_pred)
plt.figure(figsize=(6, 4))
sns.heatmap(cm, annot=True, fmt='d', xticklabels=class_names, yticklabels=class_names, cmap='Greens')
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('Confusion Matrix: InceptionV3')
plt.show()

import matplotlib.pyplot as plt
import numpy as np



# Metrics values from the classification reports
metrics = ['Accuracy', 'Precision', 'Recall', 'F1-Score']
mobilenet_v2_scores = [0.97, 0.98, 0.96, 0.97]  # MobileNetV2 values
inception_v3_scores = [0.95, 0.95, 0.95, 0.95]  # InceptionV3 values

# # Metrics values from the classification reports
# metrics = ['Accuracy', 'Precision', 'Recall', 'F1-Score']
# mobilenet_v2_scores = [0.97, 0.97, 0.96, 0.97]  # MobileNetV2 values
# inception_v3_scores = [0.95, 0.95, 0.95, 0.95]  # InceptionV3 values

x = np.arange(len(metrics))  # Number of metrics
width = 0.35  # Width of bars

# Plotting the bar chart
plt.bar(x - width/2, mobilenet_v2_scores, width, label='MobileNetV2', color='skyblue')
plt.bar(x + width/2, inception_v3_scores, width, label='InceptionV3', color='lightgreen')

# Add labels and title
plt.ylabel('Scores')
plt.title('Model Performance Comparison')
plt.xticks(x, metrics)  # Set x-axis labels
plt.legend()

# Display the chart
plt.show()

"""1. Line Chart for Metric Trends
Showcase the performance metrics for each model using a line chart.
"""

plt.plot(metrics, mobilenet_v2_scores, marker='o', label='MobileNetV2', color='blue')
plt.plot(metrics, inception_v3_scores, marker='o', label='InceptionV3', color='green')

plt.title('Model Performance Metrics')
plt.ylabel('Scores')
plt.xlabel('Metrics')
plt.grid(True, linestyle='--', alpha=0.7)
plt.legend()
plt.show()

import seaborn as sns

data = np.array([mobilenet_v2_scores, inception_v3_scores])
models = ['MobileNetV2', 'InceptionV3']

fig, ax = plt.subplots(figsize=(6, 4))
sns.heatmap(data, annot=True, fmt=".2f", cmap="YlGnBu", xticklabels=metrics, yticklabels=models, ax=ax)

plt.title('Model Performance Heatmap')
plt.xlabel('Metrics')
plt.ylabel('Models')
plt.show()

plt.pie([mobilenet_v2_scores[0], inception_v3_scores[0]],
        labels=['MobileNetV2', 'InceptionV3'],
        autopct='%1.1f%%',
        startangle=140, colors=['skyblue', 'lightgreen'])

plt.title('Accuracy Comparison')
plt.show()

"""Model        | Accuracy | Precision | Recall | F1-Score
-------------------------------------------------------
MobileNetV2  |  xx%     |  xx%      |  xx%   | xx%
InceptionV3  |  xx%     |  xx%      |  xx%   | xx%



"""

resnet_feature_extractor = hub.KerasLayer(
    "https://tfhub.dev/google/imagenet/resnet_v2_50/feature_vector/5",
    input_shape=(224, 224, 3),
    trainable=False
)

mobilenet_preds = model.predict(val_ds)
inception_preds = inception_model.predict(val_ds)
final_preds = (mobilenet_preds + inception_preds) / 2

